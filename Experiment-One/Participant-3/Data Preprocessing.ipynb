{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from glom import glom\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotionrating</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>skin_temp</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>166.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.030120</td>\n",
       "      <td>74.967677</td>\n",
       "      <td>-0.903594</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.124674</td>\n",
       "      <td>15.392030</td>\n",
       "      <td>0.176319</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>-1.317816</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.051150</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>-0.911150</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>-0.796150</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>-0.581150</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Emotionrating  heart_rate   skin_temp  userid\n",
       "count     166.000000  165.000000  165.000000   166.0\n",
       "mean        3.030120   74.967677   -0.903594     2.0\n",
       "std         2.124674   15.392030    0.176319     0.0\n",
       "min         1.000000   54.000000   -1.317816     2.0\n",
       "25%         1.000000   60.000000   -1.051150     2.0\n",
       "50%         2.000000   70.000000   -0.911150     2.0\n",
       "75%         4.000000   91.000000   -0.796150     2.0\n",
       "max         8.000000  102.333333   -0.581150     2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Extracted data 2/Tableau exp 1 data user 002.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, Load, Extract, Save Physioloigcal Signal (Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class readloadsignal:\n",
    "    \n",
    "    '''\n",
    "    This classreads and load physiological signals exported from fitbit. It extracts the heart rate (json file), estimated oxygen variation (csv file)\n",
    "    and skin temperature (csv file) and saves as seperate folders into specified directory\n",
    "    '''\n",
    "\n",
    "    def __init__(self,filename,output_name):\n",
    "        self.filename = filename\n",
    "        self.output_name = output_name\n",
    "\n",
    "    def extractvaluejson(self):\n",
    "\n",
    "        '''\n",
    "        This method reads and extracts the heartrate from the input jsonfile for heartrate from fitbit\n",
    "        '''\n",
    "\n",
    "        df = pd.read_json(self.filename)\n",
    "        df_1 = df[\"value\"].apply(lambda row:glom(row,\"bpm\"))\n",
    "        df_2 = df[\"value\"].apply(lambda row:glom(row, \"confidence\"))\n",
    "        df_3 = df[\"dateTime\"]\n",
    "        df = pd.concat([df_3, df_2, df_1], axis=1, ignore_index=True)\n",
    "        df.columns = [\"datetime\",\"heartrate\",\"confidence\"] #rename column\n",
    "        df.set_index(\"datetime\",inplace=True)\n",
    "        df = df.loc[\"2022-06-21 14:33:00\": \"2022-06-21 15:29:05\"]\n",
    "        df.reset_index(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def extractvaluecsv(self):\n",
    "\n",
    "        '''\n",
    "        This method reads and extracts the skintemp and estimated oxygen variation from the input csv files from fitbit\n",
    "        '''\n",
    "\n",
    "        column_dict = {\"timestamp\":\"datetime\", \"recorded_time\":\"datetime\", \"dateTime\":\"datetime\"}\n",
    "\n",
    "        df = pd.read_csv(self.filename)\n",
    "        df.rename(columns=column_dict, inplace=True)\n",
    "        df[\"datetime\"] = pd.to_datetime(df.datetime)\n",
    "        df.set_index(\"datetime\", inplace=True)\n",
    "        df = df.loc[\"2022-06-21 14:33:00\": \"2022-06-21 15:29:05\"]\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def savesignal(self):\n",
    "\n",
    "        '''\n",
    "        This method saves each extracted physiological signal as a sepreate csv into specified directory\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            df = self.extractvaluejson()\n",
    "        except ValueError:\n",
    "            df = self.extractvaluecsv()\n",
    "        df.to_csv('Extracted data 2/{}.csv'.format(self.output_name))\n",
    "        print(\"signal successfully saved\")\n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heart Rate - Exp 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal successfully saved\n"
     ]
    }
   ],
   "source": [
    "df_hr = readloadsignal(\"MyFitbitData_Zihan/Zihan/Physical Activity/heart_rate-2022-06-21.json\",\"df_hr\")\n",
    "df_hr.extractvaluejson()\n",
    "df_hr.savesignal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skin Temperature Exp 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal successfully saved\n"
     ]
    }
   ],
   "source": [
    "df_skt = readloadsignal(\"MyFitbitData_Zihan/Zihan/Sleep/Wrist Temperature - 2022-06-21.csv\",\"df_skt\")\n",
    "df_skt.extractvaluecsv()\n",
    "df_skt.savesignal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Estimated O2 Variation Exp 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal successfully saved\n"
     ]
    }
   ],
   "source": [
    "df_eo = readloadsignal(\"MyFitbitData_Zihan/Zihan/Other/estimated_oxygen_variation-2022-06-21.csv\",\"df_eo\")\n",
    "df_eo.extractvaluecsv()\n",
    "df_eo.savesignal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation (Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aligndatset:\n",
    "\n",
    "    '''\n",
    "    Argument: In positional order takes in extracted csvs of heart rate, estimated oxygen variation, skin temperature from the readloadsignal class.\n",
    "            Followed by excel file of data label and intended name of combined dataset created \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,filenamecsv1,filenamecsv2,filenamecsv3, filenameexcel,final_df):\n",
    "        self.filenamecsv1 = filenamecsv1\n",
    "        self.filenamecsv2 = filenamecsv2\n",
    "        self.filenamecsv3 = filenamecsv3\n",
    "        self.filenameexcel = filenameexcel\n",
    "        self.final_df = final_df \n",
    "\n",
    "    def read_clean_signals (self):\n",
    "\n",
    "        '''\n",
    "        This method  reads the first three csv entered and saves created dataframes into a list\n",
    "        '''\n",
    "\n",
    "        csv_files = [self.filenamecsv1, self.filenamecsv2, self.filenamecsv3]\n",
    "        dfs = []\n",
    "\n",
    "        for csv in csv_files:\n",
    "            column_droplist = [\"Unnamed: 0\"]\n",
    "            df  = pd.read_csv(csv)\n",
    "            df.drop(column_droplist,axis=1,inplace=True)\n",
    "            df[\"datetime\"] = pd.to_datetime(df.datetime)\n",
    "            dfs.append(df)\n",
    "        return dfs\n",
    "\n",
    "    def merge_signals(self):\n",
    "\n",
    "        '''\n",
    "        This method merges the the three dataframes obatined from the readcleansignal method call on date time using closest key align technique\n",
    "        '''\n",
    "\n",
    "        column_renamelist = {\"Infrared to Red Signal Ratio\":\"est_02_variation\", \"temperature\":\"skin_temp\",\"confidence\":\"heart_rate\"}\n",
    "        column_droplist = [\"heartrate\"]\n",
    "        df1, df2, df3 = self.read_clean_signals()\n",
    "        \n",
    "        # print (df1)\n",
    "        # print (df2)\n",
    "        # print (df3)\n",
    "\n",
    "        df_total = pd.merge_asof(df1, df2, on=\"datetime\",direction=\"backward\",\\\n",
    "            tolerance=pd.Timedelta(seconds = 60),allow_exact_matches=True)\n",
    "        df_total = pd.merge_asof(df_total,df3, on=\"datetime\",direction=\"nearest\",\\\n",
    "            tolerance=pd.Timedelta(seconds = 60),allow_exact_matches=True)\n",
    "        df_total.rename(columns=column_renamelist, inplace=True)\n",
    "        df_total.drop(column_droplist, inplace=True, axis=1)\n",
    "\n",
    "        return df_total\n",
    "\n",
    "    def load_datalabel(self):\n",
    "\n",
    "        '''\n",
    "        This method reads the data label excel file and divides into three dataframes using specified datetimes peculiar to this project\n",
    "        '''\n",
    "        \n",
    "        #Load and extract data label\n",
    "        df_dl = pd.read_excel(self.filenameexcel)\n",
    "        df_dl.drop([\"UserID\",\"Soundgroupselection\"], axis=1, inplace=True)\n",
    "        df_dl[[\"Starttime\", \"Endtime\"]] = df_dl[[\"Starttime\",\"Endtime\"]].apply(pd.to_datetime)\n",
    "        df_dl[\"datetime\"] = df_dl[\"Starttime\"] + timedelta(seconds = 6)\n",
    "        \n",
    "        #Create 3 dataframe with different time frames\n",
    "\n",
    "        #Dataframe with Starttime\n",
    "        df_dl_start = df_dl.drop([\"datetime\",\"Endtime\"], axis=1)\n",
    "        df_dl_start.rename(columns={\"Starttime\":\"datetime\"}, inplace=True)\n",
    "\n",
    "        #Dataframe with starttime plus six seconds\n",
    "        df_dl_after6sec = df_dl.drop([\"Starttime\",\"Endtime\"], axis=1)\n",
    "\n",
    "        #Dataframe with endtime\n",
    "        df_dl_end = df_dl.drop([\"datetime\",\"Starttime\"], axis=1)\n",
    "        df_dl_end.rename(columns={\"Endtime\":\"datetime\"},inplace=True)\n",
    "\n",
    "        return df_dl_start, df_dl_after6sec, df_dl_end\n",
    "\n",
    "    def initial_dataset_merge (self):\n",
    "\n",
    "        '''\n",
    "        This method performs an inital merge using the three dataframes (created by the load_datalabel method call) and combined physiological\n",
    "        signal dataframe (created by the merge_signal method call). Returns three unique dataframe of physiological signals merged to \n",
    "        the three data label dataframes\n",
    "        '''\n",
    "\n",
    "        df_dl_start, df_dl_after6sec, df_dl_end = self.load_datalabel()\n",
    "        df_total = self. merge_signals()\n",
    "\n",
    "        df_dataset_1 = pd.merge_asof(df_dl_start, df_total, on=\"datetime\",direction=\"nearest\", tolerance=pd.Timedelta(seconds=3),allow_exact_matches=True)\n",
    "\n",
    "        df_dataset_2 = pd.merge_asof(df_dl_after6sec, df_total, on=\"datetime\",direction=\"nearest\", tolerance=pd.Timedelta(seconds=3),allow_exact_matches=True)\n",
    "       \n",
    "        df_dataset_3 = pd.merge_asof(df_dl_end, df_total, on=\"datetime\",direction=\"nearest\", tolerance=pd.Timedelta(seconds=3),allow_exact_matches=True)\n",
    "        # print (\"1\", df_dataset_1)\n",
    "        # print (\"2\", df_dataset_2)\n",
    "        # print (\"3\", df_dataset_3)\n",
    "        return df_dataset_1, df_dataset_2, df_dataset_3\n",
    "\n",
    "    def final_dataset_merge (self):\n",
    "\n",
    "        '''\n",
    "        This method uses the combines the  three dataframes returned by the initial_dataset_merge method call and groups by selected key columns\n",
    "        and generates required statistical features.\n",
    "\n",
    "        '''\n",
    "\n",
    "        df_dataset_1, df_dataset_2, df_dataset_3 = self.initial_dataset_merge()\n",
    "        df_dataset = pd.concat([df_dataset_1,df_dataset_2,df_dataset_3])\n",
    "        df_dataset.sort_values(by=[\"SoundID\"], inplace=True)\n",
    "\n",
    "        #Groupby soundid and datetime\n",
    "        df_dataset = df_dataset.groupby([\"SoundID\",\"datetime\",\"Emotion\",\"Soundgroup\"]).mean()\n",
    "        df_dataset.sort_values(\"datetime\",inplace=True)\n",
    "        df_dataset.reset_index(inplace=True)\n",
    "        print(df_dataset)\n",
    "\n",
    "        #derive statistical features\n",
    "        try:\n",
    "            df_dataset = df_dataset.groupby([\"SoundID\"]).agg({\"datetime\":max, \"Emotionrating\":\"mean\",\"Emotion\":max,\"Soundgroup\":max, \"heart_rate\":['mean', 'std'],\n",
    "                                    \"skin_temp\":['mean', \"std\"]})\n",
    "        except KeyError:\n",
    "            print('error')\n",
    "            # df_dataset = df_dataset.groupby([\"SoundID\"]).agg({\"datetime\":max, \"Emotionrating\":\"mean\",\"Emotion\":max, \"heart_rate\":['mean', 'std'],\n",
    "            #                                 \"skin_temp\":['mean', \"std\"]})\n",
    "        return df_dataset\n",
    "\n",
    "    def save_final_dataset (self):\n",
    "\n",
    "        '''\n",
    "        This method saves the combined and final dataset created by the final_data_set_merge method call into a specified directory\n",
    "        '''\n",
    "        \n",
    "        df = self.final_dataset_merge()\n",
    "        df.to_csv('Extracted data 2/{}.csv'.format(self.final_df))\n",
    "        print (\"combined dataset successfully created\")\n",
    "        print(df.head())\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User 002 - First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SoundID            datetime  Emotion Soundgroup  Emotionrating  \\\n",
      "0    0109_2 2022-06-17 14:58:11     Fear   Practice            7.0   \n",
      "1    0109_2 2022-06-17 14:58:17     Fear   Practice            7.0   \n",
      "2    0109_2 2022-06-17 14:58:23     Fear   Practice            7.0   \n",
      "3    0153_2 2022-06-21 14:33:03     Fear     Animal            3.0   \n",
      "4    0153_2 2022-06-21 14:33:09     Fear     Animal            3.0   \n",
      "..      ...                 ...      ...        ...            ...   \n",
      "493  1366_2 2022-06-21 15:28:44  Sadness  Transport            1.0   \n",
      "494  1366_2 2022-06-21 15:28:49  Sadness  Transport            1.0   \n",
      "495  1377_2 2022-06-21 15:28:52  Sadness  Transport            1.0   \n",
      "496  1377_2 2022-06-21 15:28:58  Sadness  Transport            1.0   \n",
      "497  1377_2 2022-06-21 15:29:01  Sadness  Transport            1.0   \n",
      "\n",
      "     heart_rate  skin_temp  \n",
      "0           NaN        NaN  \n",
      "1           NaN        NaN  \n",
      "2           NaN        NaN  \n",
      "3          60.0   -0.64115  \n",
      "4          59.0   -0.64115  \n",
      "..          ...        ...  \n",
      "493        54.0   -1.25115  \n",
      "494        55.0   -1.25115  \n",
      "495        55.0   -1.25115  \n",
      "496        58.0   -1.35115  \n",
      "497        58.0   -1.35115  \n",
      "\n",
      "[498 rows x 7 columns]\n",
      "    SoundID            datetime  Emotion Soundgroup  Emotionrating  \\\n",
      "0    0109_2 2022-06-17 14:58:11     Fear   Practice            7.0   \n",
      "1    0109_2 2022-06-17 14:58:17     Fear   Practice            7.0   \n",
      "2    0109_2 2022-06-17 14:58:23     Fear   Practice            7.0   \n",
      "3    0153_2 2022-06-21 14:33:03     Fear     Animal            3.0   \n",
      "4    0153_2 2022-06-21 14:33:09     Fear     Animal            3.0   \n",
      "..      ...                 ...      ...        ...            ...   \n",
      "493  1366_2 2022-06-21 15:28:44  Sadness  Transport            1.0   \n",
      "494  1366_2 2022-06-21 15:28:49  Sadness  Transport            1.0   \n",
      "495  1377_2 2022-06-21 15:28:52  Sadness  Transport            1.0   \n",
      "496  1377_2 2022-06-21 15:28:58  Sadness  Transport            1.0   \n",
      "497  1377_2 2022-06-21 15:29:01  Sadness  Transport            1.0   \n",
      "\n",
      "     heart_rate  skin_temp  \n",
      "0           NaN        NaN  \n",
      "1           NaN        NaN  \n",
      "2           NaN        NaN  \n",
      "3          60.0   -0.64115  \n",
      "4          59.0   -0.64115  \n",
      "..          ...        ...  \n",
      "493        54.0   -1.25115  \n",
      "494        55.0   -1.25115  \n",
      "495        55.0   -1.25115  \n",
      "496        58.0   -1.35115  \n",
      "497        58.0   -1.35115  \n",
      "\n",
      "[498 rows x 7 columns]\n",
      "combined dataset successfully created\n",
      "                   datetime Emotionrating    Emotion Soundgroup heart_rate  \\\n",
      "                        max          mean        max        max       mean   \n",
      "SoundID                                                                      \n",
      "0085_2  2022-06-21 15:15:58           4.0  Happiness  Transport       88.0   \n",
      "0109_2  2022-06-17 14:58:23           7.0       Fear   Practice        NaN   \n",
      "0123_2  2022-06-21 14:47:02           7.0  Happiness     Nature       67.0   \n",
      "0149_2  2022-06-21 14:47:23           3.0    Sadness     Nature       58.0   \n",
      "0153_2  2022-06-21 14:33:15           3.0       Fear     Animal       59.0   \n",
      "\n",
      "                  skin_temp            \n",
      "              std      mean       std  \n",
      "SoundID                                \n",
      "0085_2   2.828427 -1.066150  0.000000  \n",
      "0109_2        NaN       NaN       NaN  \n",
      "0123_2   1.000000 -0.904483  0.014434  \n",
      "0149_2   2.000000 -0.921150  0.000000  \n",
      "0153_2   1.000000 -0.641150  0.000000  \n"
     ]
    }
   ],
   "source": [
    "df_combined= aligndatset(\"Extracted data 2/df_hr.csv\",\"Extracted data 2/df_skt.csv\",\"Extracted data 2/df_eo.csv\",\"Excel Database 2.xlsx\",\"df_combinedined_userzihan_exp001\" )\n",
    "df_combined.read_clean_signals()\n",
    "df_combined.merge_signals()\n",
    "df_combined.load_datalabel()\n",
    "df_combined.initial_dataset_merge()\n",
    "df_combined.final_dataset_merge()\n",
    "df_combined.save_final_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
